{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VGG块\n",
    "1. 使用3x3的卷积，深但窄的效果更好，选择更窄的3x3，而不是5x5和其他\n",
    "2. 3x3的卷积，padding = 1， n层，m个通道\n",
    "# 总结\n",
    "1. VGG使用可重复使用的卷积块来构建深度卷积神经网络\n",
    "2. 不同的卷积快个数和超参数可以得到不同复杂度的变种"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ac22be0ac350efc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:43:42.597017Z",
     "start_time": "2024-04-28T08:43:41.428365Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels) : \n",
    "    layers = []\n",
    "    for _ in range(num_convs) : \n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "# 一共5块，每一次块相当于高宽减半， 输入维度是224*224， 除5次2之后就变成了7\n",
    "\n",
    "def vgg(conv_arch) : \n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    for(num_convs, out_channels) in conv_arch : \n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels = out_channels\n",
    "    return nn.Sequential(*conv_blks, nn.Flatten(),\n",
    "                         nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(),\n",
    "                         nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(),\n",
    "                         nn.Dropout(0.5), nn.Linear(4096, 10))\n",
    "\n",
    "net = vgg(conv_arch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:51:45.354984Z",
     "start_time": "2024-04-28T08:51:44.944889Z"
    }
   },
   "id": "4fa093ca3b127052"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential Output shape:\t torch.Size([1, 64, 112, 112])\n",
      "Sequential Output shape:\t torch.Size([1, 128, 56, 56])\n",
      "Sequential Output shape:\t torch.Size([1, 256, 28, 28])\n",
      "Sequential Output shape:\t torch.Size([1, 512, 14, 14])\n",
      "Sequential Output shape:\t torch.Size([1, 512, 7, 7])\n",
      "Flatten Output shape:\t torch.Size([1, 25088])\n",
      "Linear Output shape:\t torch.Size([1, 4096])\n",
      "ReLU Output shape:\t torch.Size([1, 4096])\n",
      "Dropout Output shape:\t torch.Size([1, 4096])\n",
      "Linear Output shape:\t torch.Size([1, 4096])\n",
      "ReLU Output shape:\t torch.Size([1, 4096])\n",
      "Dropout Output shape:\t torch.Size([1, 4096])\n",
      "Linear Output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#  观察每个层输出的形状\n",
    "X = torch.randn(1, 1, 224, 224)\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__, 'Output shape:\\t', X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:52:43.827340Z",
     "start_time": "2024-04-28T08:52:43.719781Z"
    }
   },
   "id": "fd779b6bd79e4206"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
